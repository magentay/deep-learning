{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DataSet: Experimental Data for Question Classification\n",
    "    \n",
    "webpage:    http://cogcomp.org/Data/QA/QC/\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_1000.label',\n",
       " 'train_2000.label',\n",
       " 'train_3000.label',\n",
       " 'train_4000.label',\n",
       " 'train_5500.label',\n",
       " 'TREC_10.label']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "datadir = '/data/question'\n",
    "os.listdir(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size:  5452\n",
      "test set size:  500\n"
     ]
    }
   ],
   "source": [
    "def clean_text(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"i 'm\", \"i am\", string)\n",
    "    string = re.sub(r\"he 's\", \"he is\", string)\n",
    "    string = re.sub(r\"she 's\", \"she is\", string)\n",
    "    string = re.sub(r\"it 's\", \"it is\", string)\n",
    "    string = re.sub(r\"that's\", \"that is\", string)\n",
    "    string = re.sub(r\"what 's\", \"what is\", string)\n",
    "    string = re.sub(r\"where 's\", \"where is\", string)\n",
    "    string = re.sub(r\"how 's\", \"how is\", string)\n",
    "    string = re.sub(r\"won't\", \"will not\", string)\n",
    "    string = re.sub(r\"can't\", \"cannot\", string)\n",
    "    string = re.sub(r\"n't\", \" not\", string)\n",
    "    \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def load_data(filename):\n",
    "    file = os.path.join(datadir,filename)\n",
    "    f = open(file, 'rb')\n",
    "\n",
    "    labels_low = []\n",
    "    labels_high = []\n",
    "    sentences = []\n",
    "    for line in f.readlines():\n",
    "        label, sentence = line.decode('windows-1252').split(maxsplit=1)\n",
    "        label_h = label.split(\":\")[0]\n",
    "        labels_low.append(label)\n",
    "        labels_high.append(label_h)\n",
    "        sentences.append(clean_text(sentence))\n",
    "    \n",
    "    return sentences, labels_low, labels_high\n",
    "\n",
    "\n",
    "sentences_train, labels_low_train, labels_high_train = load_data('train_5500.label')\n",
    "sentences_test, labels_low_test, labels_high_test = load_data('TREC_10.label')\n",
    "\n",
    "print(\"train set size: \", len(sentences_train))\n",
    "print(\"test set size: \", len(sentences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ENTY': 1250, 'HUM': 1223, 'DESC': 1162, 'NUM': 896, 'LOC': 835, 'ABBR': 86})\n"
     ]
    }
   ],
   "source": [
    "# Count the high level labels\n",
    "counter=collections.Counter(labels_high_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'HUM:ind': 962, 'LOC:other': 464, 'DESC:def': 421, 'NUM:count': 363, 'DESC:manner': 276, 'DESC:desc': 274, 'NUM:date': 218, 'ENTY:other': 217, 'ENTY:cremat': 207, 'DESC:reason': 191, 'HUM:gr': 189, 'LOC:country': 155, 'LOC:city': 129, 'ENTY:animal': 112, 'ENTY:food': 103, 'ENTY:dismed': 103, 'ENTY:termeq': 93, 'NUM:period': 75, 'NUM:money': 71, 'ABBR:exp': 70, 'LOC:state': 66, 'ENTY:sport': 62, 'ENTY:event': 56, 'NUM:other': 52, 'HUM:desc': 47, 'ENTY:product': 42, 'ENTY:substance': 41, 'ENTY:color': 40, 'ENTY:techmeth': 38, 'NUM:dist': 34, 'NUM:perc': 27, 'ENTY:veh': 27, 'ENTY:word': 26, 'HUM:title': 25, 'LOC:mount': 21, 'ABBR:abb': 16, 'ENTY:lang': 16, 'ENTY:body': 16, 'NUM:volsize': 13, 'ENTY:plant': 13, 'ENTY:symbol': 11, 'NUM:weight': 11, 'ENTY:instru': 10, 'NUM:code': 9, 'ENTY:letter': 9, 'NUM:speed': 9, 'NUM:temp': 8, 'NUM:ord': 6, 'ENTY:currency': 4, 'ENTY:religion': 4})\n"
     ]
    }
   ],
   "source": [
    "# Count the low level labels\n",
    "counter=collections.Counter(labels_low_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing -- tokenizing and pading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 40\n",
    "max_features = 2000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "x_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode for the labels\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(labels_high_test)\n",
    "y_train = encoder.transform(labels_high_train)\n",
    "y_test = encoder.transform(labels_high_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for queries dataset\n",
    "\n",
    "### bi-directional LSTM models\n",
    "Given the nature of search engine queries, the order of the words is not as organized as speech, so the model that can carry information both forward and backward could be beneficial. \n",
    "\n",
    "### CNN models\n",
    "Given the property of search engine queries, semi-random word orders and limited word length per classification task, the mechanism of Convolutional neural network seems to be a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# performance measures\n",
    "\n",
    "\n",
    "$Accuracy =\\frac{ \\text{#  of correctly predicted query intents}}{\\text{Total # of queries}}$\n",
    "\n",
    "\n",
    "$Precision_i =\n",
    "\\frac{\\text{# of correctly predicted intents with the intent i}}\n",
    "{\\text{Total # of predicted intents with the intent i}}$\n",
    "\n",
    "$Recall_i =\n",
    "\\frac{\\text{# of correctly predicted intents with the intent i}}\n",
    "{\\text{Total # of human annotated queries with the intent i}} $\n",
    "\n",
    "$F\\text{-}score_i = 2 ×\n",
    "\\frac{Precision_i × Recall_i}{Precision_i + Recall_i}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Recall metric for multi-label classification \n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Precision metric for multi-label classification of\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding:\n",
    "\n",
    "use vectors from GloVe as initial values for the matched query words. For query words that do not exist in GloVe vocabulary, the vectors will be initialized with random values using Xavier initializer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1: CNN Model (1d convolution)\n",
    "\n",
    "<img style=\"float: left;\" src=\"img_files/cnn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 40)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 40, 50)        100000      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 40, 50)        0           embedding[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 38, 20)        3020        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 37, 20)        4020        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 36, 20)        5020        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)   (None, 19, 20)        0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)   (None, 18, 20)        0           conv1d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)   (None, 18, 20)        0           conv1d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 380)           0           max_pooling1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 360)           0           max_pooling1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 360)           0           max_pooling1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 1100)          0           flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "                                                                   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1100)          0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 50)            55050       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 6)             306         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 167,416\n",
      "Trainable params: 167,416\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Conv1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "sequence_length = maxlen\n",
    "embedding_dim = 50\n",
    "dropout_prob = 0.5\n",
    "num_filters = 20\n",
    "hidden_dims = 50\n",
    "\n",
    "input_shape = (sequence_length,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(max_features, embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob)(z)\n",
    "\n",
    "# Convolutional block\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Conv1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "    \n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob)(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(6, activation=\"softmax\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\",f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5452 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "5452/5452 [==============================] - 0s - loss: 1.6593 - categorical_accuracy: 0.2489 - f1: nan - val_loss: 1.5897 - val_categorical_accuracy: 0.3700 - val_f1: nan\n",
      "Epoch 2/50\n",
      "5452/5452 [==============================] - 0s - loss: 1.4469 - categorical_accuracy: 0.4116 - f1: nan - val_loss: 1.1842 - val_categorical_accuracy: 0.5140 - val_f1: 0.4521\n",
      "Epoch 3/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.9780 - categorical_accuracy: 0.6473 - f1: 0.5356 - val_loss: 0.7395 - val_categorical_accuracy: 0.7540 - val_f1: 0.7233\n",
      "Epoch 4/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.6759 - categorical_accuracy: 0.7663 - f1: 0.7492 - val_loss: 0.6142 - val_categorical_accuracy: 0.8000 - val_f1: 0.8002\n",
      "Epoch 5/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.5131 - categorical_accuracy: 0.8338 - f1: 0.8241 - val_loss: 0.5627 - val_categorical_accuracy: 0.8420 - val_f1: 0.8338\n",
      "Epoch 6/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.4240 - categorical_accuracy: 0.8617 - f1: 0.8613 - val_loss: 0.4924 - val_categorical_accuracy: 0.8320 - val_f1: 0.8491\n",
      "Epoch 7/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.3790 - categorical_accuracy: 0.8760 - f1: 0.8731 - val_loss: 0.4969 - val_categorical_accuracy: 0.8320 - val_f1: 0.8455\n",
      "Epoch 8/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.3191 - categorical_accuracy: 0.8960 - f1: 0.8971 - val_loss: 0.4857 - val_categorical_accuracy: 0.8480 - val_f1: 0.8572\n",
      "Epoch 9/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.2942 - categorical_accuracy: 0.9024 - f1: 0.9051 - val_loss: 0.4724 - val_categorical_accuracy: 0.8600 - val_f1: 0.8552\n",
      "Epoch 10/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.2582 - categorical_accuracy: 0.9180 - f1: 0.9167 - val_loss: 0.4836 - val_categorical_accuracy: 0.8480 - val_f1: 0.8548\n",
      "Epoch 11/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.2491 - categorical_accuracy: 0.9173 - f1: 0.9185 - val_loss: 0.4730 - val_categorical_accuracy: 0.8560 - val_f1: 0.8613\n",
      "Epoch 12/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.2309 - categorical_accuracy: 0.9259 - f1: 0.9255 - val_loss: 0.4531 - val_categorical_accuracy: 0.8680 - val_f1: 0.8699\n",
      "Epoch 13/50\n",
      "5452/5452 [==============================] - 1s - loss: 0.2085 - categorical_accuracy: 0.9329 - f1: 0.9310 - val_loss: 0.4600 - val_categorical_accuracy: 0.8620 - val_f1: 0.8572\n",
      "Epoch 14/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1896 - categorical_accuracy: 0.9402 - f1: 0.9395 - val_loss: 0.4609 - val_categorical_accuracy: 0.8800 - val_f1: 0.8759\n",
      "Epoch 15/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1836 - categorical_accuracy: 0.9437 - f1: 0.9427 - val_loss: 0.4728 - val_categorical_accuracy: 0.8680 - val_f1: 0.8707\n",
      "Epoch 16/50\n",
      "5452/5452 [==============================] - 1s - loss: 0.1717 - categorical_accuracy: 0.9457 - f1: 0.9442 - val_loss: 0.4806 - val_categorical_accuracy: 0.8640 - val_f1: 0.8669\n",
      "Epoch 17/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1620 - categorical_accuracy: 0.9468 - f1: 0.9471 - val_loss: 0.4771 - val_categorical_accuracy: 0.8620 - val_f1: 0.8662\n",
      "Epoch 18/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1586 - categorical_accuracy: 0.9474 - f1: 0.9481 - val_loss: 0.4633 - val_categorical_accuracy: 0.8580 - val_f1: 0.8664\n",
      "Epoch 19/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1585 - categorical_accuracy: 0.9488 - f1: 0.9490 - val_loss: 0.4534 - val_categorical_accuracy: 0.8720 - val_f1: 0.8731\n",
      "Epoch 20/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1551 - categorical_accuracy: 0.9519 - f1: 0.9516 - val_loss: 0.4683 - val_categorical_accuracy: 0.8720 - val_f1: 0.8768\n",
      "Epoch 21/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1328 - categorical_accuracy: 0.9554 - f1: 0.9562 - val_loss: 0.4889 - val_categorical_accuracy: 0.8720 - val_f1: 0.8824\n",
      "Epoch 22/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1254 - categorical_accuracy: 0.9595 - f1: 0.9592 - val_loss: 0.5029 - val_categorical_accuracy: 0.8700 - val_f1: 0.8718\n",
      "Epoch 23/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1285 - categorical_accuracy: 0.9624 - f1: 0.9619 - val_loss: 0.4792 - val_categorical_accuracy: 0.8740 - val_f1: 0.8743\n",
      "Epoch 24/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1284 - categorical_accuracy: 0.9578 - f1: 0.9589 - val_loss: 0.5087 - val_categorical_accuracy: 0.8700 - val_f1: 0.8747\n",
      "Epoch 25/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1323 - categorical_accuracy: 0.9582 - f1: 0.9594 - val_loss: 0.4987 - val_categorical_accuracy: 0.8740 - val_f1: 0.8780\n",
      "Epoch 26/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1228 - categorical_accuracy: 0.9629 - f1: 0.9619 - val_loss: 0.4965 - val_categorical_accuracy: 0.8700 - val_f1: 0.8805\n",
      "Epoch 27/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1151 - categorical_accuracy: 0.9629 - f1: 0.9630 - val_loss: 0.5213 - val_categorical_accuracy: 0.8760 - val_f1: 0.8785\n",
      "Epoch 28/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1050 - categorical_accuracy: 0.9663 - f1: 0.9662 - val_loss: 0.5185 - val_categorical_accuracy: 0.8640 - val_f1: 0.8676\n",
      "Epoch 29/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1128 - categorical_accuracy: 0.9629 - f1: 0.9629 - val_loss: 0.5047 - val_categorical_accuracy: 0.8660 - val_f1: 0.8754\n",
      "Epoch 30/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1044 - categorical_accuracy: 0.9661 - f1: 0.9665 - val_loss: 0.4975 - val_categorical_accuracy: 0.8600 - val_f1: 0.8695\n",
      "Epoch 31/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1102 - categorical_accuracy: 0.9661 - f1: 0.9669 - val_loss: 0.4924 - val_categorical_accuracy: 0.8640 - val_f1: 0.8684\n",
      "Epoch 32/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1040 - categorical_accuracy: 0.9664 - f1: 0.9664 - val_loss: 0.5022 - val_categorical_accuracy: 0.8680 - val_f1: 0.8724\n",
      "Epoch 33/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0979 - categorical_accuracy: 0.9655 - f1: 0.9657 - val_loss: 0.5172 - val_categorical_accuracy: 0.8660 - val_f1: 0.8720\n",
      "Epoch 34/50\n",
      "5452/5452 [==============================] - 1s - loss: 0.1042 - categorical_accuracy: 0.9655 - f1: 0.9665 - val_loss: 0.5156 - val_categorical_accuracy: 0.8700 - val_f1: 0.8746\n",
      "Epoch 35/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0939 - categorical_accuracy: 0.9683 - f1: 0.9684 - val_loss: 0.5442 - val_categorical_accuracy: 0.8680 - val_f1: 0.8695\n",
      "Epoch 36/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1000 - categorical_accuracy: 0.9688 - f1: 0.9701 - val_loss: 0.5251 - val_categorical_accuracy: 0.8700 - val_f1: 0.8721\n",
      "Epoch 37/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.1000 - categorical_accuracy: 0.9688 - f1: 0.9692 - val_loss: 0.5412 - val_categorical_accuracy: 0.8640 - val_f1: 0.8708\n",
      "Epoch 38/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0938 - categorical_accuracy: 0.9710 - f1: 0.9709 - val_loss: 0.5540 - val_categorical_accuracy: 0.8660 - val_f1: 0.8701\n",
      "Epoch 39/50\n",
      "5452/5452 [==============================] - 1s - loss: 0.0924 - categorical_accuracy: 0.9701 - f1: 0.9704 - val_loss: 0.5556 - val_categorical_accuracy: 0.8660 - val_f1: 0.8718\n",
      "Epoch 40/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0948 - categorical_accuracy: 0.9705 - f1: 0.9709 - val_loss: 0.5453 - val_categorical_accuracy: 0.8640 - val_f1: 0.8717\n",
      "Epoch 41/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0783 - categorical_accuracy: 0.9745 - f1: 0.9740 - val_loss: 0.5903 - val_categorical_accuracy: 0.8660 - val_f1: 0.8694\n",
      "Epoch 42/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0890 - categorical_accuracy: 0.9721 - f1: 0.9720 - val_loss: 0.5664 - val_categorical_accuracy: 0.8640 - val_f1: 0.8683\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452/5452 [==============================] - 0s - loss: 0.0821 - categorical_accuracy: 0.9747 - f1: 0.9749 - val_loss: 0.5643 - val_categorical_accuracy: 0.8660 - val_f1: 0.8683\n",
      "Epoch 44/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0863 - categorical_accuracy: 0.9708 - f1: 0.9713 - val_loss: 0.5713 - val_categorical_accuracy: 0.8660 - val_f1: 0.8683\n",
      "Epoch 45/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0841 - categorical_accuracy: 0.9710 - f1: 0.9716 - val_loss: 0.5782 - val_categorical_accuracy: 0.8580 - val_f1: 0.8666\n",
      "Epoch 46/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0756 - categorical_accuracy: 0.9778 - f1: 0.9777 - val_loss: 0.6138 - val_categorical_accuracy: 0.8640 - val_f1: 0.8701\n",
      "Epoch 47/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0920 - categorical_accuracy: 0.9710 - f1: 0.9712 - val_loss: 0.5659 - val_categorical_accuracy: 0.8660 - val_f1: 0.8698\n",
      "Epoch 48/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0864 - categorical_accuracy: 0.9732 - f1: 0.9731 - val_loss: 0.5641 - val_categorical_accuracy: 0.8640 - val_f1: 0.8679\n",
      "Epoch 49/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0812 - categorical_accuracy: 0.9749 - f1: 0.9747 - val_loss: 0.5601 - val_categorical_accuracy: 0.8700 - val_f1: 0.8748\n",
      "Epoch 50/50\n",
      "5452/5452 [==============================] - 0s - loss: 0.0723 - categorical_accuracy: 0.9756 - f1: 0.9765 - val_loss: 0.5990 - val_categorical_accuracy: 0.8640 - val_f1: 0.8681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31440d69b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),  verbose =1, shuffle=True,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: BLSTM\n",
    "<img style=\"float: left;\" src=\"img_files/blstm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 40, 50)            100000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40, 64)            21248     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 146,470\n",
      "Trainable params: 146,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Conv1D, Embedding, Bidirectional, LSTM\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "sequence_length = maxlen\n",
    "embedding_dim = 50\n",
    "dropout_prob = 0.5\n",
    "unit_size = 32\n",
    "\n",
    "input_shape = (sequence_length,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(max_features, embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob)(z)\n",
    "\n",
    "z = Bidirectional(LSTM(unit_size, return_sequences=True))(z)\n",
    "z = Bidirectional(LSTM(unit_size))(z)\n",
    "\n",
    "model_output = Dense(6, activation=\"softmax\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\",f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5452 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "5452/5452 [==============================] - 7s - loss: 1.6306 - categorical_accuracy: 0.2959 - f1: nan - val_loss: 1.3698 - val_categorical_accuracy: 0.4320 - val_f1: 0.0901\n",
      "Epoch 2/50\n",
      "5452/5452 [==============================] - 6s - loss: 1.1259 - categorical_accuracy: 0.5807 - f1: 0.3975 - val_loss: 0.9366 - val_categorical_accuracy: 0.6700 - val_f1: 0.4389\n",
      "Epoch 3/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.6989 - categorical_accuracy: 0.7579 - f1: 0.7386 - val_loss: 0.6340 - val_categorical_accuracy: 0.7940 - val_f1: 0.7972\n",
      "Epoch 4/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.4965 - categorical_accuracy: 0.8393 - f1: 0.8364 - val_loss: 0.5330 - val_categorical_accuracy: 0.8200 - val_f1: 0.8191\n",
      "Epoch 5/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.4162 - categorical_accuracy: 0.8665 - f1: 0.8675 - val_loss: 0.5101 - val_categorical_accuracy: 0.8440 - val_f1: 0.8536\n",
      "Epoch 6/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.3637 - categorical_accuracy: 0.8828 - f1: 0.8855 - val_loss: 0.5127 - val_categorical_accuracy: 0.8540 - val_f1: 0.8607\n",
      "Epoch 7/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.3262 - categorical_accuracy: 0.8940 - f1: 0.8954 - val_loss: 0.4858 - val_categorical_accuracy: 0.8420 - val_f1: 0.8502\n",
      "Epoch 8/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.2794 - categorical_accuracy: 0.9110 - f1: 0.9117 - val_loss: 0.5002 - val_categorical_accuracy: 0.8440 - val_f1: 0.8508\n",
      "Epoch 9/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.2452 - categorical_accuracy: 0.9259 - f1: 0.9261 - val_loss: 0.4176 - val_categorical_accuracy: 0.8520 - val_f1: 0.8609\n",
      "Epoch 10/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.2246 - categorical_accuracy: 0.9321 - f1: 0.9312 - val_loss: 0.4816 - val_categorical_accuracy: 0.8620 - val_f1: 0.8614\n",
      "Epoch 11/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.2061 - categorical_accuracy: 0.9386 - f1: 0.9394 - val_loss: 0.4418 - val_categorical_accuracy: 0.8640 - val_f1: 0.8612\n",
      "Epoch 12/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1886 - categorical_accuracy: 0.9457 - f1: 0.9452 - val_loss: 0.4970 - val_categorical_accuracy: 0.8620 - val_f1: 0.8673\n",
      "Epoch 13/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1717 - categorical_accuracy: 0.9485 - f1: 0.9488 - val_loss: 0.4333 - val_categorical_accuracy: 0.8640 - val_f1: 0.8683\n",
      "Epoch 14/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1568 - categorical_accuracy: 0.9525 - f1: 0.9525 - val_loss: 0.4533 - val_categorical_accuracy: 0.8660 - val_f1: 0.8678\n",
      "Epoch 15/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1524 - categorical_accuracy: 0.9545 - f1: 0.9546 - val_loss: 0.4744 - val_categorical_accuracy: 0.8720 - val_f1: 0.8723\n",
      "Epoch 16/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1347 - categorical_accuracy: 0.9576 - f1: 0.9581 - val_loss: 0.5130 - val_categorical_accuracy: 0.8620 - val_f1: 0.8660\n",
      "Epoch 17/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1389 - categorical_accuracy: 0.9589 - f1: 0.9592 - val_loss: 0.4460 - val_categorical_accuracy: 0.8680 - val_f1: 0.8740\n",
      "Epoch 18/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1469 - categorical_accuracy: 0.9563 - f1: 0.9551 - val_loss: 0.4924 - val_categorical_accuracy: 0.8680 - val_f1: 0.8675\n",
      "Epoch 19/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1228 - categorical_accuracy: 0.9640 - f1: 0.9633 - val_loss: 0.4909 - val_categorical_accuracy: 0.8640 - val_f1: 0.8652\n",
      "Epoch 20/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1209 - categorical_accuracy: 0.9622 - f1: 0.9624 - val_loss: 0.5265 - val_categorical_accuracy: 0.8720 - val_f1: 0.8772\n",
      "Epoch 21/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1206 - categorical_accuracy: 0.9626 - f1: 0.9629 - val_loss: 0.4626 - val_categorical_accuracy: 0.8740 - val_f1: 0.8778\n",
      "Epoch 22/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1184 - categorical_accuracy: 0.9652 - f1: 0.9646 - val_loss: 0.4881 - val_categorical_accuracy: 0.8700 - val_f1: 0.8686\n",
      "Epoch 23/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1046 - categorical_accuracy: 0.9688 - f1: 0.9688 - val_loss: 0.5048 - val_categorical_accuracy: 0.8680 - val_f1: 0.8722\n",
      "Epoch 24/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1038 - categorical_accuracy: 0.9712 - f1: 0.9696 - val_loss: 0.5243 - val_categorical_accuracy: 0.8640 - val_f1: 0.8660\n",
      "Epoch 25/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0997 - categorical_accuracy: 0.9697 - f1: 0.9695 - val_loss: 0.5481 - val_categorical_accuracy: 0.8620 - val_f1: 0.8617\n",
      "Epoch 26/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1030 - categorical_accuracy: 0.9668 - f1: 0.9668 - val_loss: 0.4863 - val_categorical_accuracy: 0.8680 - val_f1: 0.8716\n",
      "Epoch 27/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1057 - categorical_accuracy: 0.9657 - f1: 0.9652 - val_loss: 0.5240 - val_categorical_accuracy: 0.8580 - val_f1: 0.8611\n",
      "Epoch 28/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0937 - categorical_accuracy: 0.9721 - f1: 0.9715 - val_loss: 0.5444 - val_categorical_accuracy: 0.8700 - val_f1: 0.8706\n",
      "Epoch 29/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0929 - categorical_accuracy: 0.9723 - f1: 0.9727 - val_loss: 0.5244 - val_categorical_accuracy: 0.8580 - val_f1: 0.8610\n",
      "Epoch 30/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0994 - categorical_accuracy: 0.9705 - f1: 0.9699 - val_loss: 0.5196 - val_categorical_accuracy: 0.8600 - val_f1: 0.8665\n",
      "Epoch 31/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0947 - categorical_accuracy: 0.9732 - f1: 0.9732 - val_loss: 0.4867 - val_categorical_accuracy: 0.8720 - val_f1: 0.8753\n",
      "Epoch 32/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0880 - categorical_accuracy: 0.9727 - f1: 0.9721 - val_loss: 0.5330 - val_categorical_accuracy: 0.8700 - val_f1: 0.8675\n",
      "Epoch 33/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0905 - categorical_accuracy: 0.9718 - f1: 0.9718 - val_loss: 0.5032 - val_categorical_accuracy: 0.8760 - val_f1: 0.8773\n",
      "Epoch 34/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0871 - categorical_accuracy: 0.9727 - f1: 0.9728 - val_loss: 0.5167 - val_categorical_accuracy: 0.8760 - val_f1: 0.8763\n",
      "Epoch 35/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0811 - categorical_accuracy: 0.9743 - f1: 0.9745 - val_loss: 0.5131 - val_categorical_accuracy: 0.8700 - val_f1: 0.8689\n",
      "Epoch 36/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0706 - categorical_accuracy: 0.9773 - f1: 0.9775 - val_loss: 0.4793 - val_categorical_accuracy: 0.8740 - val_f1: 0.8775\n",
      "Epoch 37/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0768 - categorical_accuracy: 0.9752 - f1: 0.9758 - val_loss: 0.5273 - val_categorical_accuracy: 0.8640 - val_f1: 0.8657\n",
      "Epoch 38/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0751 - categorical_accuracy: 0.9756 - f1: 0.9755 - val_loss: 0.5736 - val_categorical_accuracy: 0.8720 - val_f1: 0.8735\n",
      "Epoch 39/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0794 - categorical_accuracy: 0.9752 - f1: 0.9751 - val_loss: 0.5295 - val_categorical_accuracy: 0.8700 - val_f1: 0.8743\n",
      "Epoch 40/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0670 - categorical_accuracy: 0.9780 - f1: 0.9778 - val_loss: 0.5694 - val_categorical_accuracy: 0.8680 - val_f1: 0.8676\n",
      "Epoch 41/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0760 - categorical_accuracy: 0.9769 - f1: 0.9767 - val_loss: 0.4989 - val_categorical_accuracy: 0.8780 - val_f1: 0.8796\n",
      "Epoch 42/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0699 - categorical_accuracy: 0.9765 - f1: 0.9771 - val_loss: 0.5656 - val_categorical_accuracy: 0.8740 - val_f1: 0.8765\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452/5452 [==============================] - 6s - loss: 0.0652 - categorical_accuracy: 0.9789 - f1: 0.9784 - val_loss: 0.5079 - val_categorical_accuracy: 0.8680 - val_f1: 0.8694\n",
      "Epoch 44/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0701 - categorical_accuracy: 0.9780 - f1: 0.9783 - val_loss: 0.5177 - val_categorical_accuracy: 0.8780 - val_f1: 0.8789\n",
      "Epoch 45/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0686 - categorical_accuracy: 0.9793 - f1: 0.9789 - val_loss: 0.5234 - val_categorical_accuracy: 0.8740 - val_f1: 0.8746\n",
      "Epoch 46/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0626 - categorical_accuracy: 0.9800 - f1: 0.9800 - val_loss: 0.5471 - val_categorical_accuracy: 0.8680 - val_f1: 0.8676\n",
      "Epoch 47/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0633 - categorical_accuracy: 0.9800 - f1: 0.9796 - val_loss: 0.5584 - val_categorical_accuracy: 0.8740 - val_f1: 0.8726\n",
      "Epoch 48/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0652 - categorical_accuracy: 0.9787 - f1: 0.9788 - val_loss: 0.5310 - val_categorical_accuracy: 0.8760 - val_f1: 0.8772\n",
      "Epoch 49/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0572 - categorical_accuracy: 0.9804 - f1: 0.9813 - val_loss: 0.5620 - val_categorical_accuracy: 0.8820 - val_f1: 0.8818\n",
      "Epoch 50/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.0635 - categorical_accuracy: 0.9791 - f1: 0.9784 - val_loss: 0.5382 - val_categorical_accuracy: 0.8760 - val_f1: 0.8758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f312e8f2ef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),  verbose =1, shuffle=True,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL: C-BLSTM\n",
    "\n",
    "<img style=\"float: left;\" src=\"img_files/cblstm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling1d_4/Squeeze:0\", shape=(?, 19, 20), dtype=float32)\n",
      "Tensor(\"max_pooling1d_5/Squeeze:0\", shape=(?, 18, 20), dtype=float32)\n",
      "Tensor(\"max_pooling1d_6/Squeeze:0\", shape=(?, 18, 20), dtype=float32)\n",
      "(?, 55, 20)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 40)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 40, 50)        100000      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 40, 50)        0           embedding[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 38, 20)        3020        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 37, 20)        4020        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 36, 20)        5020        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 19, 20)        0           conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 18, 20)        0           conv1d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)   (None, 18, 20)        0           conv1d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 55, 20)        0           max_pooling1d_4[0][0]            \n",
      "                                                                   max_pooling1d_5[0][0]            \n",
      "                                                                   max_pooling1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional)  (None, 64)            13568       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 6)             390         bidirectional_3[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 126,018\n",
      "Trainable params: 126,018\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Conv1D, Embedding, Bidirectional, LSTM\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "sequence_length = maxlen\n",
    "embedding_dim = 50\n",
    "num_filters = 20\n",
    "unit_size = 32\n",
    "dropout_prob = 0.5\n",
    "\n",
    "input_shape = (sequence_length,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(max_features, embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob)(z)\n",
    "\n",
    "# Convolutional block\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Conv1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "#     conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "    print(conv)\n",
    "    \n",
    "z = Concatenate(axis=1)(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "print(z.get_shape())\n",
    "z = Bidirectional(LSTM(unit_size))(z)\n",
    "\n",
    "model_output = Dense(6, activation=\"softmax\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\",f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5452 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "5452/5452 [==============================] - 5s - loss: 1.6589 - categorical_accuracy: 0.2551 - f1: nan - val_loss: 1.5736 - val_categorical_accuracy: 0.3540 - val_f1: nan\n",
      "Epoch 2/50\n",
      "5452/5452 [==============================] - 4s - loss: 1.3463 - categorical_accuracy: 0.4795 - f1: nan - val_loss: 0.9745 - val_categorical_accuracy: 0.6460 - val_f1: 0.6101\n",
      "Epoch 3/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.7677 - categorical_accuracy: 0.7476 - f1: 0.6935 - val_loss: 0.6686 - val_categorical_accuracy: 0.7900 - val_f1: 0.7704\n",
      "Epoch 4/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.5259 - categorical_accuracy: 0.8351 - f1: 0.8290 - val_loss: 0.5519 - val_categorical_accuracy: 0.8340 - val_f1: 0.8320\n",
      "Epoch 5/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.4150 - categorical_accuracy: 0.8663 - f1: 0.8654 - val_loss: 0.5340 - val_categorical_accuracy: 0.8340 - val_f1: 0.8324\n",
      "Epoch 6/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.3355 - categorical_accuracy: 0.8953 - f1: 0.8936 - val_loss: 0.5374 - val_categorical_accuracy: 0.8200 - val_f1: 0.8235\n",
      "Epoch 7/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.2935 - categorical_accuracy: 0.9024 - f1: 0.9039 - val_loss: 0.4627 - val_categorical_accuracy: 0.8680 - val_f1: 0.8651\n",
      "Epoch 8/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.2511 - categorical_accuracy: 0.9167 - f1: 0.9175 - val_loss: 0.4846 - val_categorical_accuracy: 0.8540 - val_f1: 0.8552\n",
      "Epoch 9/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.2162 - categorical_accuracy: 0.9288 - f1: 0.9313 - val_loss: 0.4982 - val_categorical_accuracy: 0.8540 - val_f1: 0.8503\n",
      "Epoch 10/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.2016 - categorical_accuracy: 0.9364 - f1: 0.9375 - val_loss: 0.4985 - val_categorical_accuracy: 0.8480 - val_f1: 0.8508\n",
      "Epoch 11/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.1914 - categorical_accuracy: 0.9387 - f1: 0.9401 - val_loss: 0.5017 - val_categorical_accuracy: 0.8520 - val_f1: 0.8537\n",
      "Epoch 12/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.1651 - categorical_accuracy: 0.9446 - f1: 0.9455 - val_loss: 0.4853 - val_categorical_accuracy: 0.8520 - val_f1: 0.8598\n",
      "Epoch 13/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.1496 - categorical_accuracy: 0.9543 - f1: 0.9533 - val_loss: 0.4396 - val_categorical_accuracy: 0.8620 - val_f1: 0.8677\n",
      "Epoch 14/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1419 - categorical_accuracy: 0.9554 - f1: 0.9548 - val_loss: 0.4578 - val_categorical_accuracy: 0.8700 - val_f1: 0.8689\n",
      "Epoch 15/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1335 - categorical_accuracy: 0.9587 - f1: 0.9592 - val_loss: 0.4423 - val_categorical_accuracy: 0.8760 - val_f1: 0.8751\n",
      "Epoch 16/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1171 - categorical_accuracy: 0.9650 - f1: 0.9645 - val_loss: 0.4611 - val_categorical_accuracy: 0.8760 - val_f1: 0.8732\n",
      "Epoch 17/50\n",
      "5452/5452 [==============================] - 6s - loss: 0.1110 - categorical_accuracy: 0.9679 - f1: 0.9672 - val_loss: 0.4494 - val_categorical_accuracy: 0.8740 - val_f1: 0.8730\n",
      "Epoch 18/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1096 - categorical_accuracy: 0.9652 - f1: 0.9665 - val_loss: 0.4821 - val_categorical_accuracy: 0.8700 - val_f1: 0.8684\n",
      "Epoch 19/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1059 - categorical_accuracy: 0.9664 - f1: 0.9681 - val_loss: 0.4827 - val_categorical_accuracy: 0.8720 - val_f1: 0.8752\n",
      "Epoch 20/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0924 - categorical_accuracy: 0.9738 - f1: 0.9734 - val_loss: 0.4679 - val_categorical_accuracy: 0.8720 - val_f1: 0.8744\n",
      "Epoch 21/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0921 - categorical_accuracy: 0.9721 - f1: 0.9724 - val_loss: 0.4410 - val_categorical_accuracy: 0.8880 - val_f1: 0.8807\n",
      "Epoch 22/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0868 - categorical_accuracy: 0.9729 - f1: 0.9733 - val_loss: 0.4867 - val_categorical_accuracy: 0.8680 - val_f1: 0.8701\n",
      "Epoch 23/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0832 - categorical_accuracy: 0.9749 - f1: 0.9748 - val_loss: 0.4868 - val_categorical_accuracy: 0.8780 - val_f1: 0.8719\n",
      "Epoch 24/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0853 - categorical_accuracy: 0.9718 - f1: 0.9715 - val_loss: 0.4901 - val_categorical_accuracy: 0.8760 - val_f1: 0.8731\n",
      "Epoch 25/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0721 - categorical_accuracy: 0.9789 - f1: 0.9787 - val_loss: 0.4940 - val_categorical_accuracy: 0.8760 - val_f1: 0.8768\n",
      "Epoch 26/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0755 - categorical_accuracy: 0.9776 - f1: 0.9784 - val_loss: 0.4970 - val_categorical_accuracy: 0.8840 - val_f1: 0.8855\n",
      "Epoch 27/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0757 - categorical_accuracy: 0.9782 - f1: 0.9772 - val_loss: 0.4914 - val_categorical_accuracy: 0.8780 - val_f1: 0.8813\n",
      "Epoch 28/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0724 - categorical_accuracy: 0.9773 - f1: 0.9772 - val_loss: 0.5110 - val_categorical_accuracy: 0.8740 - val_f1: 0.8747\n",
      "Epoch 29/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0687 - categorical_accuracy: 0.9789 - f1: 0.9795 - val_loss: 0.5011 - val_categorical_accuracy: 0.8780 - val_f1: 0.8818\n",
      "Epoch 30/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0709 - categorical_accuracy: 0.9793 - f1: 0.9793 - val_loss: 0.5163 - val_categorical_accuracy: 0.8820 - val_f1: 0.8822\n",
      "Epoch 31/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0644 - categorical_accuracy: 0.9802 - f1: 0.9806 - val_loss: 0.5427 - val_categorical_accuracy: 0.8740 - val_f1: 0.8755\n",
      "Epoch 32/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0648 - categorical_accuracy: 0.9802 - f1: 0.9803 - val_loss: 0.5233 - val_categorical_accuracy: 0.8820 - val_f1: 0.8807\n",
      "Epoch 33/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0607 - categorical_accuracy: 0.9822 - f1: 0.9818 - val_loss: 0.5375 - val_categorical_accuracy: 0.8740 - val_f1: 0.8799\n",
      "Epoch 34/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.0581 - categorical_accuracy: 0.9822 - f1: 0.9825 - val_loss: 0.5441 - val_categorical_accuracy: 0.8780 - val_f1: 0.8786\n",
      "Epoch 35/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0580 - categorical_accuracy: 0.9811 - f1: 0.9817 - val_loss: 0.5590 - val_categorical_accuracy: 0.8740 - val_f1: 0.8729\n",
      "Epoch 36/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0574 - categorical_accuracy: 0.9828 - f1: 0.9827 - val_loss: 0.5584 - val_categorical_accuracy: 0.8780 - val_f1: 0.8837\n",
      "Epoch 37/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0590 - categorical_accuracy: 0.9828 - f1: 0.9829 - val_loss: 0.5624 - val_categorical_accuracy: 0.8860 - val_f1: 0.8831\n",
      "Epoch 38/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0522 - categorical_accuracy: 0.9829 - f1: 0.9827 - val_loss: 0.6082 - val_categorical_accuracy: 0.8680 - val_f1: 0.8681\n",
      "Epoch 39/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0640 - categorical_accuracy: 0.9782 - f1: 0.9782 - val_loss: 0.5416 - val_categorical_accuracy: 0.8840 - val_f1: 0.8854\n",
      "Epoch 40/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0535 - categorical_accuracy: 0.9835 - f1: 0.9832 - val_loss: 0.5538 - val_categorical_accuracy: 0.8860 - val_f1: 0.8855\n",
      "Epoch 41/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0601 - categorical_accuracy: 0.9796 - f1: 0.9798 - val_loss: 0.5991 - val_categorical_accuracy: 0.8740 - val_f1: 0.8795\n",
      "Epoch 42/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0542 - categorical_accuracy: 0.9817 - f1: 0.9820 - val_loss: 0.5660 - val_categorical_accuracy: 0.8820 - val_f1: 0.8845\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452/5452 [==============================] - 4s - loss: 0.0466 - categorical_accuracy: 0.9851 - f1: 0.9853 - val_loss: 0.6046 - val_categorical_accuracy: 0.8800 - val_f1: 0.8824\n",
      "Epoch 44/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0521 - categorical_accuracy: 0.9828 - f1: 0.9829 - val_loss: 0.5928 - val_categorical_accuracy: 0.8820 - val_f1: 0.8832\n",
      "Epoch 45/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0494 - categorical_accuracy: 0.9850 - f1: 0.9853 - val_loss: 0.5853 - val_categorical_accuracy: 0.8880 - val_f1: 0.8893\n",
      "Epoch 46/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0461 - categorical_accuracy: 0.9848 - f1: 0.9849 - val_loss: 0.5895 - val_categorical_accuracy: 0.8800 - val_f1: 0.8825\n",
      "Epoch 47/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0475 - categorical_accuracy: 0.9837 - f1: 0.9844 - val_loss: 0.5821 - val_categorical_accuracy: 0.8860 - val_f1: 0.8885\n",
      "Epoch 48/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0474 - categorical_accuracy: 0.9837 - f1: 0.9841 - val_loss: 0.6107 - val_categorical_accuracy: 0.8800 - val_f1: 0.8836\n",
      "Epoch 49/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0468 - categorical_accuracy: 0.9857 - f1: 0.9862 - val_loss: 0.6403 - val_categorical_accuracy: 0.8740 - val_f1: 0.8771\n",
      "Epoch 50/50\n",
      "5452/5452 [==============================] - 4s - loss: 0.0454 - categorical_accuracy: 0.9859 - f1: 0.9861 - val_loss: 0.6255 - val_categorical_accuracy: 0.8740 - val_f1: 0.8772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f312d0afa20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),  verbose =1, shuffle=True,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: BLSTM-2DCNN\n",
    "\n",
    "<img style=\"float: left;\" src=\"img_files/blstm2Dcnn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 40, 50)            100000    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 40, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 40, 64)            21248     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 80, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 78, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 39, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18720)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 112326    \n",
      "=================================================================\n",
      "Total params: 233,894\n",
      "Trainable params: 233,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPool2D, Conv2D, Embedding, Bidirectional, LSTM, Reshape\n",
    "\n",
    "units = 32\n",
    "conv_filters = 32\n",
    "\n",
    "sequence_length = maxlen\n",
    "embedding_dim = 50\n",
    "# dropout_prob = 0.5\n",
    "num_filters = 100\n",
    "hidden_dims = 50\n",
    "\n",
    "input_shape = (sequence_length,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(max_features, embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(0.2)(z)\n",
    "\n",
    "z = Bidirectional(LSTM(\n",
    "    units,\n",
    "    dropout=0.2,\n",
    "    recurrent_dropout=0.2,\n",
    "    return_sequences=True))(z)\n",
    "z = Reshape((2 * sequence_length, units, 1))(z)\n",
    "z = Conv2D(conv_filters, (3, 3))(z)\n",
    "z = MaxPool2D(pool_size=(2, 2))(z)\n",
    "z = Flatten()(z)\n",
    "model_output = Dense(6, activation=\"softmax\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\",f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5452 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "5452/5452 [==============================] - 7s - loss: 1.6022 - categorical_accuracy: 0.3028 - f1: nan - val_loss: 1.2600 - val_categorical_accuracy: 0.5220 - val_f1: 0.2482\n",
      "Epoch 2/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.9207 - categorical_accuracy: 0.6642 - f1: 0.5918 - val_loss: 0.6659 - val_categorical_accuracy: 0.8260 - val_f1: 0.6743\n",
      "Epoch 3/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.4820 - categorical_accuracy: 0.8395 - f1: 0.8353 - val_loss: 0.4839 - val_categorical_accuracy: 0.8540 - val_f1: 0.8524\n",
      "Epoch 4/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.3344 - categorical_accuracy: 0.8898 - f1: 0.8885 - val_loss: 0.4461 - val_categorical_accuracy: 0.8640 - val_f1: 0.8672\n",
      "Epoch 5/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.2494 - categorical_accuracy: 0.9149 - f1: 0.9162 - val_loss: 0.4864 - val_categorical_accuracy: 0.8600 - val_f1: 0.8610\n",
      "Epoch 6/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.1929 - categorical_accuracy: 0.9386 - f1: 0.9374 - val_loss: 0.3887 - val_categorical_accuracy: 0.8800 - val_f1: 0.8799\n",
      "Epoch 7/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.1500 - categorical_accuracy: 0.9508 - f1: 0.9512 - val_loss: 0.4778 - val_categorical_accuracy: 0.8660 - val_f1: 0.8718\n",
      "Epoch 8/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.1414 - categorical_accuracy: 0.9534 - f1: 0.9546 - val_loss: 0.4603 - val_categorical_accuracy: 0.8600 - val_f1: 0.8663\n",
      "Epoch 9/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.1180 - categorical_accuracy: 0.9622 - f1: 0.9622 - val_loss: 0.4675 - val_categorical_accuracy: 0.8660 - val_f1: 0.8651\n",
      "Epoch 10/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.1036 - categorical_accuracy: 0.9697 - f1: 0.9695 - val_loss: 0.4884 - val_categorical_accuracy: 0.8680 - val_f1: 0.8641\n",
      "Epoch 11/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0978 - categorical_accuracy: 0.9685 - f1: 0.9682 - val_loss: 0.5137 - val_categorical_accuracy: 0.8600 - val_f1: 0.8634\n",
      "Epoch 12/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0852 - categorical_accuracy: 0.9710 - f1: 0.9709 - val_loss: 0.5353 - val_categorical_accuracy: 0.8720 - val_f1: 0.8741\n",
      "Epoch 13/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0870 - categorical_accuracy: 0.9712 - f1: 0.9721 - val_loss: 0.4973 - val_categorical_accuracy: 0.8720 - val_f1: 0.8764\n",
      "Epoch 14/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0774 - categorical_accuracy: 0.9745 - f1: 0.9751 - val_loss: 0.5587 - val_categorical_accuracy: 0.8620 - val_f1: 0.8680\n",
      "Epoch 15/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0692 - categorical_accuracy: 0.9769 - f1: 0.9768 - val_loss: 0.5665 - val_categorical_accuracy: 0.8740 - val_f1: 0.8759\n",
      "Epoch 16/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0618 - categorical_accuracy: 0.9826 - f1: 0.9822 - val_loss: 0.5935 - val_categorical_accuracy: 0.8760 - val_f1: 0.8793\n",
      "Epoch 17/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0661 - categorical_accuracy: 0.9798 - f1: 0.9788 - val_loss: 0.6410 - val_categorical_accuracy: 0.8660 - val_f1: 0.8679\n",
      "Epoch 18/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0574 - categorical_accuracy: 0.9791 - f1: 0.9791 - val_loss: 0.6875 - val_categorical_accuracy: 0.8580 - val_f1: 0.8597\n",
      "Epoch 19/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0552 - categorical_accuracy: 0.9813 - f1: 0.9812 - val_loss: 0.6156 - val_categorical_accuracy: 0.8740 - val_f1: 0.8744\n",
      "Epoch 20/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0549 - categorical_accuracy: 0.9833 - f1: 0.9830 - val_loss: 0.6356 - val_categorical_accuracy: 0.8720 - val_f1: 0.8724\n",
      "Epoch 21/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0598 - categorical_accuracy: 0.9804 - f1: 0.9808 - val_loss: 0.5859 - val_categorical_accuracy: 0.8700 - val_f1: 0.8697\n",
      "Epoch 22/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0504 - categorical_accuracy: 0.9840 - f1: 0.9840 - val_loss: 0.7406 - val_categorical_accuracy: 0.8600 - val_f1: 0.8621\n",
      "Epoch 23/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0499 - categorical_accuracy: 0.9826 - f1: 0.9824 - val_loss: 0.6345 - val_categorical_accuracy: 0.8720 - val_f1: 0.8724\n",
      "Epoch 24/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0467 - categorical_accuracy: 0.9848 - f1: 0.9847 - val_loss: 0.6791 - val_categorical_accuracy: 0.8620 - val_f1: 0.8622\n",
      "Epoch 25/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0480 - categorical_accuracy: 0.9844 - f1: 0.9845 - val_loss: 0.6811 - val_categorical_accuracy: 0.8740 - val_f1: 0.8735\n",
      "Epoch 26/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0446 - categorical_accuracy: 0.9851 - f1: 0.9856 - val_loss: 0.6625 - val_categorical_accuracy: 0.8780 - val_f1: 0.8803\n",
      "Epoch 27/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0521 - categorical_accuracy: 0.9835 - f1: 0.9838 - val_loss: 0.7221 - val_categorical_accuracy: 0.8640 - val_f1: 0.8654\n",
      "Epoch 28/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0440 - categorical_accuracy: 0.9868 - f1: 0.9863 - val_loss: 0.6629 - val_categorical_accuracy: 0.8700 - val_f1: 0.8706\n",
      "Epoch 29/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0446 - categorical_accuracy: 0.9850 - f1: 0.9854 - val_loss: 0.7205 - val_categorical_accuracy: 0.8680 - val_f1: 0.8684\n",
      "Epoch 30/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0427 - categorical_accuracy: 0.9866 - f1: 0.9863 - val_loss: 0.6658 - val_categorical_accuracy: 0.8700 - val_f1: 0.8713\n",
      "Epoch 31/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0381 - categorical_accuracy: 0.9886 - f1: 0.9888 - val_loss: 0.6751 - val_categorical_accuracy: 0.8740 - val_f1: 0.8732\n",
      "Epoch 32/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0379 - categorical_accuracy: 0.9879 - f1: 0.9878 - val_loss: 0.7785 - val_categorical_accuracy: 0.8680 - val_f1: 0.8680\n",
      "Epoch 33/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0371 - categorical_accuracy: 0.9875 - f1: 0.9874 - val_loss: 0.6957 - val_categorical_accuracy: 0.8740 - val_f1: 0.8736\n",
      "Epoch 34/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0328 - categorical_accuracy: 0.9892 - f1: 0.9892 - val_loss: 0.7769 - val_categorical_accuracy: 0.8660 - val_f1: 0.8686\n",
      "Epoch 35/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0335 - categorical_accuracy: 0.9886 - f1: 0.9889 - val_loss: 0.7663 - val_categorical_accuracy: 0.8660 - val_f1: 0.8677\n",
      "Epoch 36/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0401 - categorical_accuracy: 0.9879 - f1: 0.9873 - val_loss: 0.7144 - val_categorical_accuracy: 0.8740 - val_f1: 0.8774\n",
      "Epoch 37/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0473 - categorical_accuracy: 0.9839 - f1: 0.9843 - val_loss: 0.7371 - val_categorical_accuracy: 0.8720 - val_f1: 0.8726\n",
      "Epoch 38/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0400 - categorical_accuracy: 0.9862 - f1: 0.9864 - val_loss: 0.7872 - val_categorical_accuracy: 0.8660 - val_f1: 0.8676\n",
      "Epoch 39/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0380 - categorical_accuracy: 0.9883 - f1: 0.9886 - val_loss: 0.7827 - val_categorical_accuracy: 0.8640 - val_f1: 0.8661\n",
      "Epoch 40/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0390 - categorical_accuracy: 0.9866 - f1: 0.9869 - val_loss: 0.7868 - val_categorical_accuracy: 0.8800 - val_f1: 0.8806\n",
      "Epoch 41/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0336 - categorical_accuracy: 0.9897 - f1: 0.9897 - val_loss: 0.7924 - val_categorical_accuracy: 0.8800 - val_f1: 0.8792\n",
      "Epoch 42/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0344 - categorical_accuracy: 0.9894 - f1: 0.9894 - val_loss: 0.8694 - val_categorical_accuracy: 0.8580 - val_f1: 0.8583\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452/5452 [==============================] - 7s - loss: 0.0376 - categorical_accuracy: 0.9857 - f1: 0.9860 - val_loss: 0.8069 - val_categorical_accuracy: 0.8620 - val_f1: 0.8640\n",
      "Epoch 44/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0284 - categorical_accuracy: 0.9914 - f1: 0.9914 - val_loss: 0.7652 - val_categorical_accuracy: 0.8700 - val_f1: 0.8707\n",
      "Epoch 45/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0315 - categorical_accuracy: 0.9903 - f1: 0.9905 - val_loss: 0.7929 - val_categorical_accuracy: 0.8660 - val_f1: 0.8655\n",
      "Epoch 46/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0325 - categorical_accuracy: 0.9895 - f1: 0.9897 - val_loss: 0.8200 - val_categorical_accuracy: 0.8660 - val_f1: 0.8660\n",
      "Epoch 47/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0277 - categorical_accuracy: 0.9908 - f1: 0.9912 - val_loss: 0.8284 - val_categorical_accuracy: 0.8700 - val_f1: 0.8713\n",
      "Epoch 48/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0336 - categorical_accuracy: 0.9890 - f1: 0.9891 - val_loss: 0.9214 - val_categorical_accuracy: 0.8560 - val_f1: 0.8577\n",
      "Epoch 49/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0314 - categorical_accuracy: 0.9905 - f1: 0.9904 - val_loss: 0.8628 - val_categorical_accuracy: 0.8660 - val_f1: 0.8694\n",
      "Epoch 50/50\n",
      "5452/5452 [==============================] - 7s - loss: 0.0288 - categorical_accuracy: 0.9914 - f1: 0.9915 - val_loss: 0.9192 - val_categorical_accuracy: 0.8640 - val_f1: 0.8665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f312cd58eb8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),  verbose =1, shuffle=True,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL: BLSTM-att\n",
    "\n",
    "<img style=\"float: left;\" src=\"img_files/blstm-att.png\">\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 40)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 40, 50)        100000      input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 40, 50)        0           embedding[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional)  (None, 40, 64)        21248       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "permute_1 (Permute)              (None, 64, 40)        0           bidirectional_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 64, 40)        1640        permute_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "permute_2 (Permute)              (None, 40, 64)        0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)            (None, 40, 64)        0           bidirectional_5[0][0]            \n",
      "                                                                   permute_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 2560)          0           multiply_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 6)             15366       flatten_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,254\n",
      "Trainable params: 138,254\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPool2D, Conv2D, Embedding, Bidirectional, LSTM, Reshape, merge, Permute, Multiply\n",
    "\n",
    "units = 32\n",
    "sequence_length = maxlen\n",
    "embedding_dim = 50\n",
    "\n",
    "input_shape = (sequence_length,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(max_features, embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(0.5)(z)\n",
    "\n",
    "z = Bidirectional(LSTM(units,return_sequences=True))(z)\n",
    "\n",
    "a = Permute((2,1))(z)\n",
    "\n",
    "a = Dense(sequence_length, activation='softmax')(a)\n",
    "a_probs = Permute((2,1))(a)\n",
    "\n",
    "a_mul = Multiply()([z, a_probs])\n",
    "a_mul = Flatten()(a_mul)\n",
    "\n",
    "model_output = Dense(6, activation=\"softmax\")(a_mul)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\",f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5452 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "5452/5452 [==============================] - 5s - loss: 1.6818 - categorical_accuracy: 0.2427 - f1: nan - val_loss: 1.5355 - val_categorical_accuracy: 0.3420 - val_f1: nan\n",
      "Epoch 2/50\n",
      "5452/5452 [==============================] - 5s - loss: 1.4120 - categorical_accuracy: 0.3843 - f1: nan - val_loss: 1.2250 - val_categorical_accuracy: 0.4760 - val_f1: 0.3739\n",
      "Epoch 3/50\n",
      "5452/5452 [==============================] - 5s - loss: 1.2314 - categorical_accuracy: 0.4565 - f1: 0.2358 - val_loss: 1.2070 - val_categorical_accuracy: 0.5020 - val_f1: 0.4283\n",
      "Epoch 4/50\n",
      "5452/5452 [==============================] - 5s - loss: 1.1292 - categorical_accuracy: 0.5347 - f1: 0.3532 - val_loss: 1.1506 - val_categorical_accuracy: 0.5640 - val_f1: 0.3441\n",
      "Epoch 5/50\n",
      "5452/5452 [==============================] - 5s - loss: 1.0345 - categorical_accuracy: 0.5871 - f1: 0.4844 - val_loss: 1.0791 - val_categorical_accuracy: 0.6260 - val_f1: 0.6010\n",
      "Epoch 6/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.9291 - categorical_accuracy: 0.6493 - f1: 0.6058 - val_loss: 0.9634 - val_categorical_accuracy: 0.6960 - val_f1: 0.7006\n",
      "Epoch 7/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.8370 - categorical_accuracy: 0.7007 - f1: 0.6846 - val_loss: 0.8786 - val_categorical_accuracy: 0.7340 - val_f1: 0.7305\n",
      "Epoch 8/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.7222 - categorical_accuracy: 0.7447 - f1: 0.7359 - val_loss: 0.7831 - val_categorical_accuracy: 0.7680 - val_f1: 0.7753\n",
      "Epoch 9/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.6232 - categorical_accuracy: 0.7858 - f1: 0.7802 - val_loss: 0.6929 - val_categorical_accuracy: 0.8060 - val_f1: 0.8055\n",
      "Epoch 10/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.5456 - categorical_accuracy: 0.8109 - f1: 0.8081 - val_loss: 0.6064 - val_categorical_accuracy: 0.7860 - val_f1: 0.8030\n",
      "Epoch 11/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.5080 - categorical_accuracy: 0.8250 - f1: 0.8248 - val_loss: 0.6343 - val_categorical_accuracy: 0.8180 - val_f1: 0.8187\n",
      "Epoch 12/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.4557 - categorical_accuracy: 0.8454 - f1: 0.8463 - val_loss: 0.6123 - val_categorical_accuracy: 0.8120 - val_f1: 0.8176\n",
      "Epoch 13/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.4097 - categorical_accuracy: 0.8608 - f1: 0.8622 - val_loss: 0.5595 - val_categorical_accuracy: 0.8340 - val_f1: 0.8314\n",
      "Epoch 14/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.3870 - categorical_accuracy: 0.8720 - f1: 0.8715 - val_loss: 0.5686 - val_categorical_accuracy: 0.8280 - val_f1: 0.8249\n",
      "Epoch 15/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.3732 - categorical_accuracy: 0.8723 - f1: 0.8740 - val_loss: 0.5578 - val_categorical_accuracy: 0.8280 - val_f1: 0.8304\n",
      "Epoch 16/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.3376 - categorical_accuracy: 0.8859 - f1: 0.8873 - val_loss: 0.5549 - val_categorical_accuracy: 0.8360 - val_f1: 0.8339\n",
      "Epoch 17/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.3104 - categorical_accuracy: 0.8967 - f1: 0.8965 - val_loss: 0.5708 - val_categorical_accuracy: 0.8240 - val_f1: 0.8297\n",
      "Epoch 18/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2964 - categorical_accuracy: 0.9024 - f1: 0.9025 - val_loss: 0.5208 - val_categorical_accuracy: 0.8280 - val_f1: 0.8390\n",
      "Epoch 19/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2736 - categorical_accuracy: 0.9109 - f1: 0.9116 - val_loss: 0.5810 - val_categorical_accuracy: 0.8220 - val_f1: 0.8304\n",
      "Epoch 20/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2755 - categorical_accuracy: 0.9103 - f1: 0.9097 - val_loss: 0.5956 - val_categorical_accuracy: 0.8260 - val_f1: 0.8246\n",
      "Epoch 21/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2629 - categorical_accuracy: 0.9127 - f1: 0.9125 - val_loss: 0.5634 - val_categorical_accuracy: 0.8440 - val_f1: 0.8406\n",
      "Epoch 22/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2351 - categorical_accuracy: 0.9220 - f1: 0.9216 - val_loss: 0.5584 - val_categorical_accuracy: 0.8500 - val_f1: 0.8463\n",
      "Epoch 23/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2333 - categorical_accuracy: 0.9279 - f1: 0.9275 - val_loss: 0.5449 - val_categorical_accuracy: 0.8480 - val_f1: 0.8483\n",
      "Epoch 24/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2153 - categorical_accuracy: 0.9329 - f1: 0.9342 - val_loss: 0.5608 - val_categorical_accuracy: 0.8380 - val_f1: 0.8391\n",
      "Epoch 25/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.2204 - categorical_accuracy: 0.9307 - f1: 0.9318 - val_loss: 0.5390 - val_categorical_accuracy: 0.8540 - val_f1: 0.8553\n",
      "Epoch 26/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1900 - categorical_accuracy: 0.9397 - f1: 0.9395 - val_loss: 0.5772 - val_categorical_accuracy: 0.8420 - val_f1: 0.8448\n",
      "Epoch 27/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1924 - categorical_accuracy: 0.9378 - f1: 0.9383 - val_loss: 0.5373 - val_categorical_accuracy: 0.8480 - val_f1: 0.8491\n",
      "Epoch 28/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1757 - categorical_accuracy: 0.9457 - f1: 0.9441 - val_loss: 0.6077 - val_categorical_accuracy: 0.8460 - val_f1: 0.8488\n",
      "Epoch 29/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1782 - categorical_accuracy: 0.9442 - f1: 0.9447 - val_loss: 0.5488 - val_categorical_accuracy: 0.8520 - val_f1: 0.8570\n",
      "Epoch 30/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1816 - categorical_accuracy: 0.9413 - f1: 0.9424 - val_loss: 0.5848 - val_categorical_accuracy: 0.8480 - val_f1: 0.8450\n",
      "Epoch 31/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1834 - categorical_accuracy: 0.9431 - f1: 0.9446 - val_loss: 0.5808 - val_categorical_accuracy: 0.8520 - val_f1: 0.8523\n",
      "Epoch 32/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1617 - categorical_accuracy: 0.9518 - f1: 0.9523 - val_loss: 0.5996 - val_categorical_accuracy: 0.8580 - val_f1: 0.8576\n",
      "Epoch 33/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1571 - categorical_accuracy: 0.9507 - f1: 0.9504 - val_loss: 0.5960 - val_categorical_accuracy: 0.8660 - val_f1: 0.8679\n",
      "Epoch 34/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1451 - categorical_accuracy: 0.9558 - f1: 0.9561 - val_loss: 0.5733 - val_categorical_accuracy: 0.8660 - val_f1: 0.8740\n",
      "Epoch 35/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1477 - categorical_accuracy: 0.9527 - f1: 0.9523 - val_loss: 0.5859 - val_categorical_accuracy: 0.8680 - val_f1: 0.8642\n",
      "Epoch 36/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1368 - categorical_accuracy: 0.9552 - f1: 0.9557 - val_loss: 0.5843 - val_categorical_accuracy: 0.8660 - val_f1: 0.8694\n",
      "Epoch 37/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1410 - categorical_accuracy: 0.9552 - f1: 0.9555 - val_loss: 0.6408 - val_categorical_accuracy: 0.8680 - val_f1: 0.8701\n",
      "Epoch 38/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1309 - categorical_accuracy: 0.9609 - f1: 0.9602 - val_loss: 0.5904 - val_categorical_accuracy: 0.8680 - val_f1: 0.8710\n",
      "Epoch 39/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1332 - categorical_accuracy: 0.9585 - f1: 0.9586 - val_loss: 0.6437 - val_categorical_accuracy: 0.8620 - val_f1: 0.8541\n",
      "Epoch 40/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1285 - categorical_accuracy: 0.9596 - f1: 0.9604 - val_loss: 0.6299 - val_categorical_accuracy: 0.8580 - val_f1: 0.8622\n",
      "Epoch 41/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1258 - categorical_accuracy: 0.9602 - f1: 0.9605 - val_loss: 0.6378 - val_categorical_accuracy: 0.8640 - val_f1: 0.8639\n",
      "Epoch 42/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1183 - categorical_accuracy: 0.9631 - f1: 0.9634 - val_loss: 0.6323 - val_categorical_accuracy: 0.8660 - val_f1: 0.8651\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452/5452 [==============================] - 5s - loss: 0.1375 - categorical_accuracy: 0.9584 - f1: 0.9586 - val_loss: 0.6272 - val_categorical_accuracy: 0.8700 - val_f1: 0.8695\n",
      "Epoch 44/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1384 - categorical_accuracy: 0.9585 - f1: 0.9584 - val_loss: 0.6230 - val_categorical_accuracy: 0.8540 - val_f1: 0.8563\n",
      "Epoch 45/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1183 - categorical_accuracy: 0.9629 - f1: 0.9635 - val_loss: 0.6037 - val_categorical_accuracy: 0.8580 - val_f1: 0.8597\n",
      "Epoch 46/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1192 - categorical_accuracy: 0.9613 - f1: 0.9629 - val_loss: 0.7022 - val_categorical_accuracy: 0.8540 - val_f1: 0.8531\n",
      "Epoch 47/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1106 - categorical_accuracy: 0.9664 - f1: 0.9664 - val_loss: 0.6362 - val_categorical_accuracy: 0.8640 - val_f1: 0.8631\n",
      "Epoch 48/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1069 - categorical_accuracy: 0.9666 - f1: 0.9674 - val_loss: 0.6231 - val_categorical_accuracy: 0.8640 - val_f1: 0.8619\n",
      "Epoch 49/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1108 - categorical_accuracy: 0.9655 - f1: 0.9654 - val_loss: 0.6567 - val_categorical_accuracy: 0.8600 - val_f1: 0.8641\n",
      "Epoch 50/50\n",
      "5452/5452 [==============================] - 5s - loss: 0.1128 - categorical_accuracy: 0.9640 - f1: 0.9644 - val_loss: 0.7073 - val_categorical_accuracy: 0.8560 - val_f1: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31256eac18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),  verbose =1, shuffle=True,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL: Character-level Convolutional Networks\n",
    "\n",
    "<img style=\"float: left;\" src=\"img_files/char_cnn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentences length of the dataset:  197\n"
     ]
    }
   ],
   "source": [
    "print(\"max sentences length of the dataset: \", max([len(s) for s in sentences_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 200\n",
    "\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\\n\"\n",
    "\n",
    "def pad_char(char_seq, padding_char=\"\"):\n",
    "    num_padding = sequence_length - len(char_seq)\n",
    "    new_char_seq = char_seq + [padding_char] * num_padding\n",
    "    return new_char_seq\n",
    "    \n",
    "def string_to_int8_conversion(char_seq, alphabet):\n",
    "    x = np.array([alphabet.find(char) for char in char_seq], dtype=np.int8)\n",
    "    return x    \n",
    "\n",
    "def pad_to_ind(sentences):\n",
    "    sentence_ind =[]\n",
    "    for s in sentences:\n",
    "        chars = pad_char(list(s))\n",
    "        sentence_ind.append( string_to_int8_conversion(chars, alphabet))\n",
    "    return sentence_ind\n",
    "\n",
    "sentences_train_ind =  pad_to_ind(sentences_train)\n",
    "sentences_test_ind =  pad_to_ind(sentences_test)\n",
    "\n",
    "\n",
    "def batch_generator(x, y, batch_size=16):\n",
    "    while True:\n",
    "        # choose batch_size random sentences / labels from the data\n",
    "        idx = np.random.randint(0, len(x), batch_size)\n",
    "        \n",
    "        feat = np.zeros(shape=[len(idx), len(alphabet), len(x[0]), 1])\n",
    "        for i, id in enumerate(idx):\n",
    "            for pos, word in enumerate(x[id]):\n",
    "                feat[i][word][pos][0] = 1\n",
    "\n",
    "        label = y[idx,:]\n",
    "        yield feat, label\n",
    "        \n",
    "\n",
    "train_gen = batch_generator(sentences_train_ind, y_train)\n",
    "test_gen = batch_generator(sentences_test_ind, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 70, 200, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 197, 64)        17984     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 65, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 62, 64)         16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 18, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 16, 128)        24704     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 14, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 12, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 368,710\n",
      "Trainable params: 368,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling2D, Conv2D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "sequence_length = 200\n",
    "num_quantized_chars=len(alphabet)\n",
    "kernel_sizes = (4, 4, 3, 3, 3, 3)\n",
    "num_filters1 = 64\n",
    "num_filters2 = 128\n",
    "dropout_prob = 0.5\n",
    "hidden_dims = 256\n",
    "\n",
    "\n",
    "model_input = Input(shape=[ num_quantized_chars, sequence_length, 1])\n",
    "\n",
    "conv1 = Conv2D(num_filters1, \n",
    "               kernel_size = (num_quantized_chars, kernel_sizes[0]),\n",
    "               strides=1, padding='Valid',activation='relu', use_bias=True)(model_input)\n",
    "pool1 = MaxPooling2D(pool_size=(1,3))(conv1)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(num_filters1, \n",
    "               kernel_size =(1, kernel_sizes[1]),\n",
    "               strides=1, padding='Valid',activation='relu', use_bias=True)(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(1,3))(conv2)\n",
    "\n",
    "conv3 = Conv2D( num_filters1,\n",
    "                kernel_size = (1, kernel_sizes[2]),\n",
    "               strides=1, padding='Valid',activation='relu', use_bias=True)(pool2)\n",
    "\n",
    "conv4 = Conv2D(num_filters2,\n",
    "               kernel_size = (1, kernel_sizes[3]),\n",
    "               strides=1, padding='Valid',activation='relu', use_bias=True)(conv3)\n",
    "\n",
    "conv5 = Conv2D(num_filters2,\n",
    "               kernel_size =(1, kernel_sizes[4]),\n",
    "               strides=1, padding='Valid',activation='relu', use_bias=True)(conv4)\n",
    "\n",
    "conv6 = Conv2D(num_filters2,\n",
    "               kernel_size = (1, kernel_sizes[5]),\n",
    "               strides=1, padding='Valid',activation='relu', use_bias=True)(conv5)\n",
    "pool6 = MaxPooling2D(pool_size=(1,3))(conv6)\n",
    "\n",
    "flat = Flatten()(pool6)\n",
    "drop1 = Dropout(dropout_prob)(flat)\n",
    "\n",
    "fc1 = Dense(hidden_dims, activation=\"relu\")(drop1)\n",
    "drop2 = Dropout(dropout_prob)(fc1)\n",
    "\n",
    "fc2 = Dense(hidden_dims, activation=\"relu\")(drop2)\n",
    "\n",
    "model_output = Dense(6, activation=\"softmax\")(fc2)\n",
    "\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\",f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 1s - loss: 1.6935 - categorical_accuracy: 0.2272 - f1: nan - val_loss: 1.7545 - val_categorical_accuracy: 0.1964 - val_f1: nan\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 1s - loss: 1.6548 - categorical_accuracy: 0.2353 - f1: nan - val_loss: 1.6223 - val_categorical_accuracy: 0.3482 - val_f1: nan\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 1s - loss: 1.6586 - categorical_accuracy: 0.2794 - f1: nan - val_loss: 1.6359 - val_categorical_accuracy: 0.3393 - val_f1: nan\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 1s - loss: 1.6135 - categorical_accuracy: 0.2926 - f1: nan - val_loss: 1.5347 - val_categorical_accuracy: 0.3571 - val_f1: nan\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 1s - loss: 1.6316 - categorical_accuracy: 0.2809 - f1: nan - val_loss: 1.6305 - val_categorical_accuracy: 0.3571 - val_f1: nan\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 1s - loss: 1.6287 - categorical_accuracy: 0.2868 - f1: nan - val_loss: 1.5862 - val_categorical_accuracy: 0.2679 - val_f1: nan\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 1s - loss: 1.6148 - categorical_accuracy: 0.2772 - f1: nan - val_loss: 1.4603 - val_categorical_accuracy: 0.4018 - val_f1: nan\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 1s - loss: 1.5724 - categorical_accuracy: 0.3162 - f1: nan - val_loss: 1.4701 - val_categorical_accuracy: 0.5089 - val_f1: nan\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 1s - loss: 1.5406 - categorical_accuracy: 0.3118 - f1: nan - val_loss: 1.3655 - val_categorical_accuracy: 0.4196 - val_f1: 0.3245\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 1s - loss: 1.5107 - categorical_accuracy: 0.3331 - f1: nan - val_loss: 1.3372 - val_categorical_accuracy: 0.4018 - val_f1: nan\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 1s - loss: 1.4612 - categorical_accuracy: 0.3529 - f1: nan - val_loss: 1.2210 - val_categorical_accuracy: 0.5089 - val_f1: 0.4154\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 1s - loss: 1.4284 - categorical_accuracy: 0.3824 - f1: nan - val_loss: 1.1948 - val_categorical_accuracy: 0.4643 - val_f1: 0.5324\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 1s - loss: 1.3169 - categorical_accuracy: 0.4485 - f1: nan - val_loss: 1.3771 - val_categorical_accuracy: 0.4375 - val_f1: 0.3025\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 1s - loss: 1.2606 - categorical_accuracy: 0.4559 - f1: nan - val_loss: 1.0924 - val_categorical_accuracy: 0.5089 - val_f1: 0.3933\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 1s - loss: 1.1759 - categorical_accuracy: 0.5162 - f1: nan - val_loss: 1.0968 - val_categorical_accuracy: 0.5000 - val_f1: 0.3887\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 1s - loss: 1.0949 - categorical_accuracy: 0.5434 - f1: nan - val_loss: 0.9732 - val_categorical_accuracy: 0.5893 - val_f1: 0.5108\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 1s - loss: 1.0422 - categorical_accuracy: 0.5728 - f1: nan - val_loss: 1.0209 - val_categorical_accuracy: 0.5893 - val_f1: 0.3417\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 1s - loss: 0.9657 - categorical_accuracy: 0.6081 - f1: 0.5028 - val_loss: 0.8880 - val_categorical_accuracy: 0.6786 - val_f1: 0.6291\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 1s - loss: 0.9639 - categorical_accuracy: 0.6272 - f1: 0.5269 - val_loss: 0.7108 - val_categorical_accuracy: 0.7232 - val_f1: 0.6137\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 1s - loss: 0.8477 - categorical_accuracy: 0.6860 - f1: 0.6209 - val_loss: 0.6955 - val_categorical_accuracy: 0.7411 - val_f1: 0.7761\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 1s - loss: 0.8033 - categorical_accuracy: 0.7096 - f1: 0.6662 - val_loss: 0.8809 - val_categorical_accuracy: 0.6964 - val_f1: 0.6521\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 1s - loss: 0.7679 - categorical_accuracy: 0.7140 - f1: 0.6737 - val_loss: 0.8220 - val_categorical_accuracy: 0.7054 - val_f1: 0.6888\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 1s - loss: 0.7172 - categorical_accuracy: 0.7419 - f1: 0.7144 - val_loss: 0.7041 - val_categorical_accuracy: 0.7500 - val_f1: 0.7335\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 1s - loss: 0.7522 - categorical_accuracy: 0.7184 - f1: 0.7070 - val_loss: 0.6918 - val_categorical_accuracy: 0.8214 - val_f1: 0.7842\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 1s - loss: 0.7238 - categorical_accuracy: 0.7338 - f1: 0.7213 - val_loss: 0.5438 - val_categorical_accuracy: 0.7857 - val_f1: 0.7881\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 1s - loss: 0.6608 - categorical_accuracy: 0.7721 - f1: 0.7594 - val_loss: 0.7977 - val_categorical_accuracy: 0.7232 - val_f1: 0.7359\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 1s - loss: 0.6785 - categorical_accuracy: 0.7581 - f1: 0.7486 - val_loss: 0.4504 - val_categorical_accuracy: 0.8304 - val_f1: 0.8384\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 1s - loss: 0.6348 - categorical_accuracy: 0.7853 - f1: 0.7790 - val_loss: 0.6086 - val_categorical_accuracy: 0.7768 - val_f1: 0.7877\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 1s - loss: 0.5796 - categorical_accuracy: 0.7956 - f1: 0.7859 - val_loss: 0.4655 - val_categorical_accuracy: 0.8661 - val_f1: 0.8625\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 1s - loss: 0.5744 - categorical_accuracy: 0.8132 - f1: 0.8046 - val_loss: 0.6908 - val_categorical_accuracy: 0.7500 - val_f1: 0.7656\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 1s - loss: 0.5270 - categorical_accuracy: 0.8169 - f1: 0.8188 - val_loss: 0.6191 - val_categorical_accuracy: 0.7946 - val_f1: 0.7828\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 1s - loss: 0.5485 - categorical_accuracy: 0.8037 - f1: 0.7961 - val_loss: 0.4543 - val_categorical_accuracy: 0.8571 - val_f1: 0.8444\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 1s - loss: 0.5771 - categorical_accuracy: 0.8044 - f1: 0.7978 - val_loss: 0.6632 - val_categorical_accuracy: 0.7679 - val_f1: 0.7532\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 1s - loss: 0.5195 - categorical_accuracy: 0.8368 - f1: 0.8312 - val_loss: 0.6263 - val_categorical_accuracy: 0.7946 - val_f1: 0.7743\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 1s - loss: 0.4981 - categorical_accuracy: 0.8360 - f1: 0.8385 - val_loss: 0.4970 - val_categorical_accuracy: 0.8482 - val_f1: 0.8197\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 1s - loss: 0.5125 - categorical_accuracy: 0.8250 - f1: 0.8277 - val_loss: 0.5081 - val_categorical_accuracy: 0.8125 - val_f1: 0.8227\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 1s - loss: 0.4701 - categorical_accuracy: 0.8551 - f1: 0.8531 - val_loss: 0.7888 - val_categorical_accuracy: 0.7411 - val_f1: 0.7453\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 1s - loss: 0.4824 - categorical_accuracy: 0.8301 - f1: 0.8310 - val_loss: 0.5155 - val_categorical_accuracy: 0.7946 - val_f1: 0.7967\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 1s - loss: 0.4653 - categorical_accuracy: 0.8426 - f1: 0.8395 - val_loss: 0.6012 - val_categorical_accuracy: 0.8214 - val_f1: 0.8076\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 1s - loss: 0.4717 - categorical_accuracy: 0.8493 - f1: 0.8505 - val_loss: 0.9545 - val_categorical_accuracy: 0.7411 - val_f1: 0.7579\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 1s - loss: 0.3955 - categorical_accuracy: 0.8676 - f1: 0.8734 - val_loss: 0.9689 - val_categorical_accuracy: 0.7143 - val_f1: 0.7237\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 1s - loss: 0.4265 - categorical_accuracy: 0.8647 - f1: 0.8592 - val_loss: 0.8390 - val_categorical_accuracy: 0.7500 - val_f1: 0.7364\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 1s - loss: 0.4051 - categorical_accuracy: 0.8699 - f1: 0.8697 - val_loss: 0.4782 - val_categorical_accuracy: 0.8482 - val_f1: 0.8445\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 1s - loss: 0.4218 - categorical_accuracy: 0.8713 - f1: 0.8689 - val_loss: 0.4676 - val_categorical_accuracy: 0.8571 - val_f1: 0.8367\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s - loss: 0.4016 - categorical_accuracy: 0.8794 - f1: 0.8778 - val_loss: 0.4845 - val_categorical_accuracy: 0.8482 - val_f1: 0.8470\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 1s - loss: 0.3755 - categorical_accuracy: 0.8816 - f1: 0.8803 - val_loss: 0.6930 - val_categorical_accuracy: 0.7679 - val_f1: 0.7544\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 1s - loss: 0.4095 - categorical_accuracy: 0.8632 - f1: 0.8650 - val_loss: 0.4396 - val_categorical_accuracy: 0.8839 - val_f1: 0.8948\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 1s - loss: 0.3483 - categorical_accuracy: 0.8860 - f1: 0.8898 - val_loss: 0.8336 - val_categorical_accuracy: 0.7232 - val_f1: 0.7385\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 1s - loss: 0.3570 - categorical_accuracy: 0.8846 - f1: 0.8906 - val_loss: 0.7978 - val_categorical_accuracy: 0.8125 - val_f1: 0.8011\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 1s - loss: 0.3984 - categorical_accuracy: 0.8779 - f1: 0.8772 - val_loss: 0.6451 - val_categorical_accuracy: 0.7679 - val_f1: 0.7588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f312544a940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "model.fit_generator(generator=train_gen,  \n",
    "                    steps_per_epoch=y_train.shape[0] // batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=test_gen,  \n",
    "                    validation_steps=y_test.shape[0] // batch_size,\n",
    "                    verbose =1,\n",
    "                    callbacks=[tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
