{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poetry_file ='poetry.txt'\n",
    "\n",
    "poetrys = []\n",
    "with open(poetry_file, \"r\", encoding='utf-8',) as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            title, content = line.strip().split(':')\n",
    "            content = content.replace(' ','')\n",
    "            if '_' in content or '(' in content or '（' in content or '《' in content or '[' in content:\n",
    "                continue\n",
    "            if len(content) < 5 or len(content) > 79:\n",
    "                continue\n",
    "            content = '[' + content + ']'\n",
    "            poetrys.append(content)\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唐诗总数:  34646\n"
     ]
    }
   ],
   "source": [
    "poetrys = sorted(poetrys,key=lambda line: len(line))\n",
    "print('唐诗总数: ', len(poetrys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words : 6109\n"
     ]
    }
   ],
   "source": [
    "# Count word freqency \n",
    "all_words = []\n",
    "for poetry in poetrys:\n",
    "    all_words += [word for word in poetry]\n",
    "counter = collections.Counter(all_words)\n",
    "count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "words, _ = zip(*count_pairs)    \n",
    "\n",
    "print(\"total words :\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = words[:len(words)] + (' ',)\n",
    "word_num_map = dict(zip(words, range(len(words))))\n",
    "\n",
    "to_num = lambda word: word_num_map.get(word, len(words))\n",
    "poetrys_vector = [ list(map(to_num, poetry)) for poetry in poetrys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = max(map(len,poetrys_vector))\n",
    "size = len(poetrys_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   3,   28,  545,  104,  720,    1,    2, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109]], dtype=int32),\n",
       " array([[  28,  545,  104,  720,    1,    2, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109, 6109,\n",
       "         6109, 6109, 6109, 6109]], dtype=int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "batch_size = 1\n",
    "n_chunk = (size-1)//batch_size +1\n",
    "\n",
    "for j in range(n_chunk):\n",
    "    ids = list(range((j*batch_size),min(size, (j+1)*batch_size)))\n",
    "\n",
    "    xdata = np.full((batch_size, length), word_num_map[' '], np.int32)\n",
    "    for i in range(len(ids)):\n",
    "        xdata[i, :len(poetrys_vector[ids[i]])] = poetrys_vector[ids[i]]\n",
    "    ydata = np.copy(xdata)\n",
    "    ydata[:,:-1] = xdata[:,1:] \n",
    "    x_batches.append(xdata)\n",
    "    y_batches.append(ydata)\n",
    "    \n",
    "x_batches[0],y_batches[0]\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = 0.75\n",
    "# batch_size = 32\n",
    "layer_size = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.002\n",
    "lr_decay = 0.97\n",
    "model_save_path = './poets_model.ckpt'\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, None])\n",
    "output_targets = tf.placeholder(tf.int32, [batch_size, None])\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(layer_size)\n",
    "drop = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([drop] * num_layers)\n",
    " \n",
    "initial_state = cell.zero_state(batch_size, tf.float32)   \n",
    "\n",
    "embedding =  tf.contrib.layers.embed_sequence(input_data, vocab_size=len(words)+1,\n",
    "    embed_dim=layer_size, scope = 'embedding')\n",
    "outputs, last_state = tf.nn.dynamic_rnn(cell, embedding, initial_state=initial_state, scope='lstm')\n",
    "outputs = tf.reshape(outputs,[-1, layer_size])\n",
    "logits = tf.contrib.layers.fully_connected(outputs,len(words)+1,activation_fn=None)\n",
    "probs = tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_word(weights):\n",
    "    t = np.cumsum(weights)\n",
    "    s = np.sum(weights)\n",
    "    sample = int(np.searchsorted(t, np.random.rand(1)*s))\n",
    "    return words[sample]\n",
    "\n",
    "def gen_poetry(sess):\n",
    "    state_ = sess.run(cell.zero_state(1, tf.float32))\n",
    "    x = np.array([list(map(word_num_map.get, '['))])\n",
    "    [probs_, state_] = sess.run([probs, last_state], feed_dict={input_data: x, initial_state: state_})\n",
    "    word = to_word(probs_)\n",
    "    #word = words[np.argmax(probs_)]\n",
    "        \n",
    "    poem = ''\n",
    "    while word != ']':\n",
    "        poem += word\n",
    "        x = np.zeros((1,1))\n",
    "        x[0,0] = word_num_map[word]\n",
    "        [probs_, state_] = sess.run([probs, last_state], feed_dict={input_data: x, initial_state: state_})\n",
    "        word = to_word(probs_)\n",
    "        #word = words[np.argmax(probs_)]\n",
    "    return poem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34646/34646 [38:48<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34645 6.35449\n",
      "散玉觜争软，清春对梦官。烟飙妆壮谬，清侣鸟凄凄。谏酡迎色式，章恩瑞雾岑。泉香三六国，三画怨塔藏，金羽喧旧医，岂似同，舞，身无诸举风，还须臂驰与送璧。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34646/34646 [37:53<00:00, 15.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 34645 6.04134\n",
      "莫耶万里分泛兮银体白宝罗，扑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34646/34646 [37:38<00:00, 15.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 34645 6.27104\n",
      "销人抱北登舟长白足送，远游风生城脂白马指荷春。娇罢宫兮听吟飞，看珠寄兮释之心归。我今词谷孟隳失，驻杳居王北阙白练。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34646/34646 [37:52<00:00, 15.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 34645 6.41668\n",
      "惆怅闲将丝子恨人，我能随来不把内气。自向长是汉门侣，鸟居相看眼地立。炭裹砚有精，种舌喷田喧。叶中世士既双死，超异浩尧凤一几。当还沈会辅王灭，恨无否学墓，何用终所昭。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34646/34646 [33:05<00:00, 17.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 34645 6.32021\n",
      "病收千里叹，长安影其难。微曈漓祖室彰浦在兮成，驯罗色来颜至在阳。证侣饮兵如，薄宠居宅？晚雪雄婺人皆渴，下界周兮剑星侧难留相兮。作经患，及千龄君于月飞辱。\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "targets = tf.reshape(output_targets, [-1])\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss([logits], [targets], [tf.ones_like(targets, dtype=tf.float32)])\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), 5)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    " \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        learning_rate = learning_rate * (lr_decay ** epoch)\n",
    "\n",
    "        for n in tqdm(range(n_chunk)):\n",
    "            train_loss, _ , _ = sess.run([loss, last_state, train_op], \n",
    "                                     feed_dict={input_data: x_batches[n], output_targets: y_batches[n]})\n",
    "     \n",
    "        print(epoch, n, train_loss)\n",
    "    \n",
    "        print(gen_poetry(sess))\n",
    " \n",
    "        saver.save(sess, model_save_path)\n",
    "        \n",
    "        \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: http://karpathy.github.io/2015/05/21/rnn-effectiveness/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
