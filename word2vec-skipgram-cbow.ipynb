{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 7,\n",
       " 'I': 0,\n",
       " 'NLP': 5,\n",
       " 'deep': 3,\n",
       " 'enjoy': 2,\n",
       " 'flying': 6,\n",
       " 'learning': 4,\n",
       " 'like': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "la = np.linalg\n",
    "\n",
    "s1 = 'I like deep learning.'\n",
    "s2 = 'I like NLP.'\n",
    "s3 = 'I enjoy flying.'\n",
    "\n",
    "words = ['I', 'like', 'enjoy', 'deep', 'learning', 'NLP', 'flying','.']\n",
    "vocab = dict([(x, y) for (y, x) in enumerate(words)])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenizer(s):\n",
    "    _WORD_SPLIT = re.compile(\"([.,!?\\\"':;)(])\")\n",
    "    sentences = re.split(_WORD_SPLIT,s )\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        if sentence:\n",
    "            words += sentence.strip().split()\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [2., 0., 0., 0., 0., 0., 2., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 2., 0., 0., 0., 0., 2.],\n",
       "       [0., 0., 0., 0., 1., 0., 2., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# window based co-occurrence matrix\n",
    "window = 2\n",
    "X = np.zeros((len(words), len(words)))\n",
    "\n",
    "for s in [s1, s3, s3]:\n",
    "    toks = tokenizer(s)\n",
    "\n",
    "    for i in range(len(toks)-1):\n",
    "        word_i = vocab[toks[i]]\n",
    "        for j in range(i+1, min(i+window,len(toks))):\n",
    "            word_j = vocab[toks[j]]\n",
    "            X[word_i][word_j] += 1\n",
    "            X[word_j][word_i] += 1\n",
    "                       \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U, s, Vh = la.svd(X, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB2nhYUNX7rcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07eca71b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(U[:,0], U[:,1], '.')\n",
    "\n",
    "for i in range(len(words)):\n",
    "    plt.text(U[i,0], U[i,1], words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The simple word2vec model\n",
    "\n",
    "cost function J\n",
    "\n",
    "$J(\\theta) = \\frac{1}{T}\\sum^T_{t=1} \\sum_{-c\\leq j\\leq c, j\\neq 0} \\log p(w_{t+j} \\big|w_{t})$\n",
    "\n",
    "with probabilities defined as: $p(w_O | w_I) = \\frac{exp({v^{'}_{w_o}}^T v_{w_I})} {\\sum_{w=1}^W exp({v^{'}_{w_o}}^T v_{w_I})}$\n",
    "\n",
    "main idea: train binary logistic regressions for a\ttrue pair (center word and word in its context window) and a couple\tof random pairs\t(the center\tword with a\trandom\tword)\t\n",
    "\n",
    "<img style=\"left;\" src=\"img_files\\skipgram1.png\">\n",
    "\n",
    "\n",
    "## Subsampling Frequent Words\n",
    "\n",
    "\n",
    "## Sampling rate\n",
    "\n",
    "* calculating a probability with which to keep a given word in the vocabulary.\n",
    "$P(w_i) = (\\sqrt{\\frac{z(w_i)}{0.001}} + 1) \\cdot\\frac{0.001}{z(w_i)}$\n",
    "* $w_i$ is the word, $z(w_i)$ is the fraction of the total words in the corpus that are that word.\n",
    "\n",
    "## Negative Sampling\n",
    "\n",
    "* having each training sample only modify a small percentage of the weights, rather than all of them.\n",
    "\n",
    "* Essentially, the probability for selecting a word as a negative sample is related to its frequency, with more frequent words being more likely to be selected as negative samples.\n",
    "$P(w_i) = \\frac{f(w_i)^{3/4}}{\\sum_{j=0}^n (f(w_j)*{3/4})}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(s):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    labels = []\n",
    "    for l in s:\n",
    "        toks = tokenizer(l)\n",
    "        for i, tok in enumerate(toks):\n",
    "            if i+1<len(toks):\n",
    "                X.append(vocab[tok])\n",
    "                Y.append(vocab[toks[i+1]])\n",
    "                labels.append(1)\n",
    "            if i-1>=0:\n",
    "                X.append(vocab[tok])\n",
    "                Y.append(vocab[toks[i-1]])\n",
    "                labels.append(1)\n",
    "           \n",
    "            idxs = []\n",
    "            \n",
    "            # negative sampling\n",
    "            while 1:\n",
    "                idx = np.random.randint(len(vocab))\n",
    "                if idx not in idxs and words[idx] not in toks:\n",
    "                    idxs.append(idx)\n",
    "                if len(idxs)>=2:\n",
    "                    break\n",
    "                        \n",
    "            for idx in idxs:\n",
    "                X.append(vocab[tok])\n",
    "                Y.append(idx)\n",
    "                labels.append(0)\n",
    "         \n",
    "    return np.array(X), np.array( Y), labels \n",
    "                \n",
    "        \n",
    "X, y, labels = get_train([s1,s2,s3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 1, 2)          16          input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 2, 1)          0           embedding[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 2, 1)          0           embedding[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dot_2 (Dot)                      (None, 1, 1)          0           reshape_1[0][0]                  \n",
      "                                                                   reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)              (None, 1)             0           dot_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             2           reshape_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 1, 2)          16          input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 2, 1)          0           embedding[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 2, 1)          0           embedding[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (2, 1, 1)             0           reshape_1[0][0]                  \n",
      "                                                                   reshape_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Reshape, merge, Dense, Dot\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "vector_dim = 2\n",
    "\n",
    "input_target = Input((1,))\n",
    "input_context = Input((1,))\n",
    "\n",
    "embedding = Embedding(vocab_size, vector_dim, input_length=1, name='embedding')\n",
    "\n",
    "target = embedding(input_target)\n",
    "target = Reshape((vector_dim, 1))(target)\n",
    "context = embedding(input_context)\n",
    "context = Reshape((vector_dim, 1))(context)\n",
    "\n",
    "# similarity = merge([target, context], mode='cos', dot_axes=0)\n",
    "similarity = Dot(axes=0, normalize = True)([target, context])\n",
    "\n",
    "# dot_product = merge([target, context], mode='dot', dot_axes=1)\n",
    "\n",
    "dot_product = Dot(axes=1)([target, context])\n",
    "dot_product = Reshape((1,))(dot_product)\n",
    "\n",
    "# add the sigmoid output layer\n",
    "output = Dense(1, activation='sigmoid')(dot_product)\n",
    "\n",
    "model = Model(inputs=[input_target, input_context], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "validation_model = Model(inputs=[input_target, input_context], outputs=similarity)\n",
    "validation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f07cd164f28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X,y], labels, batch_size=4, epochs=1000,verbose =0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I', 'learning', 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.random.choice(range(len(words)), 2)\n",
    "    \n",
    "sim = validation_model.predict_on_batch([np.array([ids[0]]), np.array([ids[1]])])\n",
    "\n",
    "words[ids[0]], words[ids[1]], sim[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBGRQBQYIiISiAJDREQC+f9OVfAkH/vRjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07cd17e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_matrix = Model(inputs=input_target, outputs= target)\n",
    "\n",
    "output = embedding_matrix.predict(np.array([range(len(words))]).reshape(-1))\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    pos = output[i]\n",
    "    plt.plot(pos[0], pos[1], 'o')\n",
    "    plt.text(pos[0], pos[1], word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous bag of\twords (CBOW):\t\n",
    "Predict\tcenter\tword from sum of surrounding word vectors instead of predicting\tsurrounding\tsingle words from center word as\tin skipgram model\n",
    "\n",
    "<img style=\"float: left;\" src=\"img_files\\cbow.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'deep', 'learning', '.']\n",
      "['I', 'like', 'NLP', '.']\n",
      "['I', 'enjoy', 'flying', '.']\n"
     ]
    }
   ],
   "source": [
    "def get_train(s):\n",
    "    \n",
    "    word_index = []\n",
    "    context = []\n",
    "    label1 = []\n",
    "    negatives = []\n",
    "    label2 = []\n",
    "    for l in s:\n",
    "        toks = tokenizer(l)\n",
    "        print(toks)\n",
    "        for i, tok in enumerate(toks):\n",
    "            \n",
    "            if i+1<len(toks) & i-1>=0:\n",
    "                word_index.append(vocab[tok])\n",
    "               \n",
    "                context.append([vocab[toks[i-1]],vocab[toks[i+1]]])\n",
    "               \n",
    "                \n",
    "                label1.append(1)\n",
    "            \n",
    "            # negative sampling\n",
    "                idxs=[]\n",
    "                while 1:\n",
    "                    idx = np.random.randint(len(vocab))\n",
    "                    if idx not in idxs and words[idx] not in toks:\n",
    "                        idxs.append(idx)\n",
    "                    if len(idxs)>=2:\n",
    "                        break\n",
    "\n",
    "               \n",
    "                negatives.append(vocab[tok])\n",
    "                label2.append(0)\n",
    "                    \n",
    "         \n",
    "    return np.array(word_index), np.array( context), np.array(label1), np.array(negatives), np.array(label2) \n",
    "                \n",
    "        \n",
    "word_index, context, label1, negatives, label2 = get_train([s1,s2,s3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7, 1],\n",
       "        [7, 1],\n",
       "        [7, 2]]), array([0, 0, 0]), array([0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context, word_index, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_52 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_53 (InputLayer)            (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)         multiple              40          input_52[0][0]                   \n",
      "                                                                   input_53[0][0]                   \n",
      "                                                                   input_54[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_54 (InputLayer)            (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, 5)             0           embedding_14[1][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dot_9 (Dot)                      (None, 1)             0           embedding_14[0][0]               \n",
      "                                                                   lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dot_10 (Dot)                     (None, 2)             0           embedding_14[2][0]               \n",
      "                                                                   lambda_11[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Multiply\n",
    "import keras.backend as K\n",
    "\n",
    "window = 1\n",
    "neg_win = 2\n",
    "EMBEDDING_DIM = 5\n",
    "\n",
    "word_index = Input(shape=(1,))\n",
    "context = Input(shape=(2*window,))\n",
    "\n",
    "negative_samples = Input(shape=(neg_win,))\n",
    "\n",
    "\n",
    "# Generate embedding matrix with all values between -1/2d, 1/2d\n",
    "embedding = np.random.uniform(-1.0 / (2 * EMBEDDING_DIM),\n",
    "                              1.0 / (2 * EMBEDDING_DIM),\n",
    "                              (len(vocab), EMBEDDING_DIM))\n",
    "\n",
    "\n",
    "# All inputs are processed through a common embedding layer\n",
    "shared_embedding_layer = (Embedding(input_dim=(len(vocab)),\n",
    "                                    output_dim=EMBEDDING_DIM,\n",
    "                                    weights=[embedding]))\n",
    "\n",
    "\n",
    "\n",
    "word_embedding = shared_embedding_layer(word_index)\n",
    "context_embeddings = shared_embedding_layer(context)\n",
    "negative_words_embedding = shared_embedding_layer(negative_samples)\n",
    "\n",
    "\n",
    "# Now the context words are averaged to get the CBOW vector\n",
    "cbow = Lambda(lambda x: K.mean(x, axis=1),\n",
    "              output_shape=(EMBEDDING_DIM,))(context_embeddings)\n",
    "\n",
    "# Context is multiplied (dot product) with current word and negative\n",
    "# sampled words\n",
    "word_context_product = Dot(axes = -1)([word_embedding, cbow])\n",
    "negative_context_product = Dot(axes = -1)([negative_words_embedding, cbow])\n",
    "\n",
    "# The dot products are outputted\n",
    "model = Model(inputs=[word_index, context, negative_samples],\n",
    "              outputs=[word_context_product, negative_context_product])\n",
    "\n",
    "# Binary crossentropy is applied on the output\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_54 to have shape (None, 2) but got array with shape (26, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c2facf5433c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_54 to have shape (None, 2) but got array with shape (26, 1)"
     ]
    }
   ],
   "source": [
    "model.fit([word_index, context, negatives], [label1, label2], batch_size=4, epochs=1000, verbose =0, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
